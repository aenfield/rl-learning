{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746ff004-5ba9-4da9-bd92-ba1f72a6ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from predibase import (\n",
    "    Predibase,\n",
    "    GRPOConfig,\n",
    "    RewardFunctionsConfig,\n",
    "    RewardFunctionsRuntimeConfig,\n",
    "    SFTConfig,\n",
    "    SamplingParamsConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i think this is because the Predibase API sometimes gives warnings for version-related stuff (it does it in the course videos too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216c8d1-2313-4f30-a948-4684c811d8f6",
   "metadata": {},
   "source": [
    "# Lesson eight: Actually do RFT via Predibase to train a model that plays Wordle, better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad8ae30-68a8-43c2-b0b1-6fd518a7f570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Connected to Predibase as </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">f66dcd85</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-7638-4ead-9487-2506bb2c930b</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">username</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">aenfield</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">@gmail.com)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mConnected to Predibase as \u001b[0m\u001b[1;35mUser\u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;34m=\u001b[0m\u001b[93mf66dcd85\u001b[0m\u001b[93m-7638-4ead-9487-2506bb2c930b\u001b[0m\u001b[1;34m, \u001b[0m\u001b[1;33musername\u001b[0m\u001b[1;34m=\u001b[0m\u001b[1;35maenfield\u001b[0m\u001b[1;34m@gmail.com\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = load_dotenv(override=True) # populate env from .env file, reload of file - 'override' - ok here\n",
    "\n",
    "pb = Predibase(api_token=os.environ['PREDIBASE_API_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b5162-53ee-4128-89f8-06dac7416889",
   "metadata": {},
   "source": [
    "Load the training data that shows how to think about answers - they said this is from strong models like more expensive versions of Claude, but w/ the actual results/answers removed - I think to help train on the 'thinking' processes. They uploaded this data to HF, from where we'll get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a8fa53-89e1-48cf-b69c-b502685f3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('predibase/wordle-grpo', split='train')\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f64f73d5-e89f-4cac-85bc-e666717999d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# and now provide/upload the data to Predibase (I guess associated w/ my own account?)\n",
    "\n",
    "try:\n",
    "    dataset = pb.datasets.from_pandas_dataframe(dataset, name='wordle-grpo-data')\n",
    "except Exception:\n",
    "    dataset = pb.datasets.get('wordle-grpo-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "903e2991-450d-41f0-98a2-3dffa3e3d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Predibase 'repo' as the structure to collect what I'm doing\n",
    "repo = pb.repos.create(name='wordle', exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74e75d-4b33-4353-b264-74ada9d6f241",
   "metadata": {},
   "source": [
    "The reward functions - more complicated than what we did in previous lessons, but still pretty straightforward. I got these from reward_functions.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d94c53f-d2c9-4ff9-bd58-c6940a28aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_format_check(prompt: str, completion: str, example: dict) -> int:\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Check if the format matches expected pattern:\n",
    "        # <think> content </think> followed by <answer> content </answer>\n",
    "        regex = (\n",
    "            r\"^<think>\\s*([^<]*(?:<(?!/?think>)[^<]*)*)\\s*<\\/think>\\n\"\n",
    "            r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        )\n",
    "\n",
    "        # Search for the regex in the completion\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 2:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[1]\n",
    "        guess = guess.strip()\n",
    "\n",
    "        # If the word is not 5 characters, return 0\n",
    "        if len(guess) != 5:\n",
    "            return 0.1\n",
    "\n",
    "        # Check if the guess is a valid word compared to a predifined list of words\n",
    "        word_list = pd.read_csv(str(example[\"word_list\"]))\n",
    "        if guess not in word_list[\"Word\"].values:\n",
    "            return 0.5\n",
    "\n",
    "        reward = 1.0\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# Reward function that checks if the guess uses the previous feedback for its next guess\n",
    "def uses_previous_feedback(prompt: str, completion: str, example: dict) -> int:\n",
    "    import re\n",
    "    import ast\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Extract the guess from the completion\n",
    "        regex = r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 1:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[0].strip()\n",
    "        if len(guess) != 5:\n",
    "            return 0.0\n",
    "\n",
    "        past_guess_history = ast.literal_eval(example[\"past_guess_history\"])\n",
    "        if len(past_guess_history) == 0:\n",
    "            print(\"Uses previous feedback reward: 0.1 (No past guesses)\")\n",
    "            return 0.1\n",
    "\n",
    "        correct_letter_to_position = {}\n",
    "        valid_letter_to_position = {}\n",
    "        wrong_letter_to_position = {}\n",
    "        for _, past_feedback in past_guess_history:\n",
    "            past_feedback = past_feedback.split(\" \")\n",
    "            for i, fb in enumerate(past_feedback):\n",
    "                if '✓' in fb:\n",
    "                    if fb[0] not in correct_letter_to_position:\n",
    "                        correct_letter_to_position[fb[0]] = set()\n",
    "                    correct_letter_to_position[fb[0]].add(i)\n",
    "                elif '-' in fb:\n",
    "                    if fb[0] not in valid_letter_to_position:\n",
    "                        valid_letter_to_position[fb[0]] = set()\n",
    "                    valid_letter_to_position[fb[0]].add(i)\n",
    "                else:\n",
    "                    if fb[0] not in wrong_letter_to_position:\n",
    "                        wrong_letter_to_position[fb[0]] = set()\n",
    "                    wrong_letter_to_position[fb[0]].add(i)\n",
    "\n",
    "        for idx, letter in enumerate(guess):\n",
    "            # Positive reward if guess reuses letter in confirmed correct position\n",
    "            if (letter in correct_letter_to_position and idx in correct_letter_to_position[letter]):\n",
    "                reward += 0.2\n",
    "            # Reward if letter known to be in word is used in a new position\n",
    "            elif (letter in valid_letter_to_position and idx not in valid_letter_to_position[letter]):\n",
    "                reward += 0.1\n",
    "            # Penalize reuse of known-in-word letter in same position (not exploring)\n",
    "            elif (letter in valid_letter_to_position and idx in valid_letter_to_position[letter]):\n",
    "                reward -= 0.2\n",
    "            # Penalize use of known-absent letter\n",
    "            elif letter in wrong_letter_to_position:\n",
    "                reward -= 0.5\n",
    "            else:\n",
    "                # Reward unknown letters with partial credit for exploration\n",
    "                reward += 0.05\n",
    "\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# Reward function that computes normalized information gain of the guess, i.e.,\n",
    "# does the new guess reduce the uncertainty of the secret word the most\n",
    "def guess_value(prompt: str, completion: str, example: dict) -> int:\n",
    "    import math\n",
    "    import re\n",
    "    import ast\n",
    "    import pandas as pd\n",
    "\n",
    "    def validate_guess(secret: str, guess: str, raw_feedback: bool = False) -> str:\n",
    "        feedback = []\n",
    "        secret_list = list(secret)\n",
    "\n",
    "        # Check for correct positions\n",
    "        for i, (g_char, s_char) in enumerate(zip(guess, secret)):\n",
    "            if g_char == s_char:\n",
    "                feedback.append(f\"{g_char}(✓) \")\n",
    "                secret_list[i] = None\n",
    "            else:\n",
    "                feedback.append(None)\n",
    "\n",
    "        # Check for misplaced letters\n",
    "        for i, g_char in enumerate(guess):\n",
    "            if feedback[i] is None:\n",
    "                if g_char in secret_list:\n",
    "                    feedback[i] = f\"{g_char}(-) \"\n",
    "                    secret_list[secret_list.index(g_char)] = None\n",
    "                else:\n",
    "                    feedback[i] = f\"{g_char}(x) \"\n",
    "\n",
    "        if raw_feedback:\n",
    "            return feedback\n",
    "        return \"\".join(feedback).strip()\n",
    "\n",
    "    def filter_candidates(all_candidate_words, past_guesses):\n",
    "        filtered = []\n",
    "        for word in all_candidate_words:\n",
    "            valid = True\n",
    "            for past_guess, past_feedback in past_guesses:\n",
    "                # Compute what the feedback would be if 'word' were the secret.\n",
    "                candidate_feedback = validate_guess(word, past_guess)\n",
    "                if candidate_feedback != past_feedback:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if valid:\n",
    "                filtered.append(word)\n",
    "        return filtered\n",
    "\n",
    "    def compute_normalized_information_gain(all_candidate_words, past_guesses, guess):\n",
    "        # First, filter the candidate words based on past guesses.\n",
    "        candidates = filter_candidates(all_candidate_words, past_guesses)\n",
    "        total_candidates = len(candidates)\n",
    "\n",
    "        # If no candidates remain, return zeros.\n",
    "        if total_candidates == 0:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        # Current uncertainty (entropy) before the guess.\n",
    "        current_entropy = math.log2(total_candidates)\n",
    "\n",
    "        # Partition candidates by the feedback pattern that would be produced by the current guess.\n",
    "        feedback_groups = {}\n",
    "        for word in candidates:\n",
    "            # Get the raw feedback list (e.g., ['B(✓) ', 'R(✓) ', 'A(x) ', ...])\n",
    "            feedback = validate_guess(word, guess, raw_feedback=True)\n",
    "            # Create a simple representation for the feedback pattern.\n",
    "            # '1' for correct position, '0' for wrong position, 'x' for letter not in word.\n",
    "            feedback_pattern = \"\".join('1' if \"✓\" in fb else ('0' if \"-\" in fb else 'x') \n",
    "                                    for fb in feedback)\n",
    "            feedback_groups.setdefault(feedback_pattern, []).append(word)\n",
    "\n",
    "        expected_entropy = 0\n",
    "        max_info_gain = 0\n",
    "        # For each feedback group, compute its contribution to the expected entropy and the info gain.\n",
    "        for group in feedback_groups.values():\n",
    "            group_size = len(group)\n",
    "            p = group_size / total_candidates\n",
    "            # Entropy if this feedback is received.\n",
    "            group_entropy = math.log2(group_size) if group_size > 0 else 0\n",
    "            expected_entropy += p * group_entropy\n",
    "            # Information gain for this feedback outcome.\n",
    "            info_gain = current_entropy - group_entropy\n",
    "            max_info_gain = max(max_info_gain, info_gain)\n",
    "\n",
    "        # The expected gain is the reduction in entropy on average.\n",
    "        expected_gain = current_entropy - expected_entropy\n",
    "\n",
    "        # Normalize by the maximum possible gain, which is current_entropy (if you reduced to one candidate).\n",
    "        normalized_expected_gain = expected_gain / current_entropy if current_entropy > 0 else 0\n",
    "        normalized_max_gain = max_info_gain / current_entropy if current_entropy > 0 else 0\n",
    "\n",
    "        return normalized_expected_gain, normalized_max_gain\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Extract the guess from the completion\n",
    "        regex = r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 1:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[0].strip()\n",
    "        if len(guess) != 5:\n",
    "            return 0.0\n",
    "\n",
    "        # Load the word list\n",
    "        word_list = pd.read_csv(str(example[\"word_list\"]))\n",
    "        if guess not in word_list[\"Word\"].values:\n",
    "            return 0.0\n",
    "\n",
    "        # Extract past guesses and feedback\n",
    "        past_guess_history = ast.literal_eval(example[\"past_guess_history\"])\n",
    "\n",
    "        # Compute normalized information gain\n",
    "        normalized_expected_gain, _ = compute_normalized_information_gain(\n",
    "            word_list[\"Word\"].values,\n",
    "            past_guess_history,\n",
    "            guess\n",
    "        )\n",
    "\n",
    "        # Compute reward based on normalized information gain\n",
    "        reward = normalized_expected_gain\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a5d15-95e6-4689-80e3-1be06e99ccb9",
   "metadata": {},
   "source": [
    "And, ok, I should be able to actually train the updated model w/ just one call. The only things I need to provide are the base model's name, to specify the reward functions (the three functions just above), give a few config params, and the dataset on which to train (the one I uploaded above). Then Predibase just goes to town, apparently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "498776d4-8f78-4218-9b2f-5bd1c6c6b0ee",
   "metadata": {},
   "outputs": [
    {
     "ename": "PredibaseResponseError",
     "evalue": "Failed to decode payload as JSON. Response status code: 500. Raw payload text: \n. Error: Expecting value: line 1 column 1 (char 0)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/uL_qiEBqr_rI798JLfwPG/lib/python3.11/site-packages/requests/models.py:974\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    973\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m974\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcomplexjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/__init__.py:346\u001b[39m, in \u001b[36mloads\u001b[39m\u001b[34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    344\u001b[39m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    345\u001b[39m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[32m--> \u001b[39m\u001b[32m346\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:337\u001b[39m, in \u001b[36mJSONDecoder.decode\u001b[39m\u001b[34m(self, s, _w)\u001b[39m\n\u001b[32m    333\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[32m    334\u001b[39m \u001b[33;03mcontaining a JSON document).\u001b[39;00m\n\u001b[32m    335\u001b[39m \n\u001b[32m    336\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m337\u001b[39m obj, end = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m end = _w(s, end).end()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.11.11-macos-aarch64-none/lib/python3.11/json/decoder.py:355\u001b[39m, in \u001b[36mJSONDecoder.raw_decode\u001b[39m\u001b[34m(self, s, idx)\u001b[39m\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[33m\"\u001b[39m\u001b[33mExpecting value\u001b[39m\u001b[33m\"\u001b[39m, s, err.value) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mJSONDecodeError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/rl-learning/rft-grpo/.venv/lib/python3.11/site-packages/predibase/_client.py:228\u001b[39m, in \u001b[36mpayload_json\u001b[39m\u001b[34m(r)\u001b[39m\n\u001b[32m    227\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m228\u001b[39m     data = \u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    230\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    231\u001b[39m         \u001b[38;5;66;03m# New APIs should always return a JSON object.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.cache/uv/archive-v0/uL_qiEBqr_rI798JLfwPG/lib/python3.11/site-packages/requests/models.py:978\u001b[39m, in \u001b[36mResponse.json\u001b[39m\u001b[34m(self, **kwargs)\u001b[39m\n\u001b[32m    975\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    976\u001b[39m     \u001b[38;5;66;03m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[39;00m\n\u001b[32m    977\u001b[39m     \u001b[38;5;66;03m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m978\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m RequestsJSONDecodeError(e.msg, e.doc, e.pos)\n",
      "\u001b[31mJSONDecodeError\u001b[39m: Expecting value: line 1 column 1 (char 0)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mPredibaseResponseError\u001b[39m                    Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfinetuning\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGRPOConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbase_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqwen2-5-7b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreward_fns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRewardFunctionsConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m            \u001b[49m\u001b[43mruntime\u001b[49m\u001b[43m=\u001b[49m\u001b[43mRewardFunctionsRuntimeConfig\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m                \u001b[49m\u001b[43mpackages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpandas\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43moutput_format_check\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_format_check\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muses_previous_feedback\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muses_previous_feedback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mguess_value\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mguess_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m        \u001b[49m\u001b[43msampling_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSamplingParamsConfig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4096\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mnum_generations\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mwordle\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mWordle GRPO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/rl-learning/rft-grpo/.venv/lib/python3.11/site-packages/predibase/resources/finetuning_jobs.py:55\u001b[39m, in \u001b[36mFinetuningJobs.create\u001b[39m\u001b[34m(self, config, dataset, continue_from_version, repo, description, watch, show_tensorboard)\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(repo, Repo):\n\u001b[32m     53\u001b[39m     repo = repo.name\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m job_resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhttp_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/v2/finetuning/jobs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     58\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparams\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdataset\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontinueFromVersion\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinue_from_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrepo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrepo\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdescription\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     63\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     64\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m job = FinetuningJob.model_validate(job_resp)\n\u001b[32m     67\u001b[39m \u001b[38;5;28mprint\u001b[39m(\n\u001b[32m     68\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSuccessfully requested finetuning of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.base_model\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m from \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     69\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33mbase\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mcontinue_from_version\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39mcontinue_from_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m as `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.target_repo\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m/\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     70\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.target_version_tag\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m`. (Job UUID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjob.uuid\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m).\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m     71\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/rl-learning/rft-grpo/.venv/lib/python3.11/site-packages/predibase/_client.py:166\u001b[39m, in \u001b[36mPredibase.http_post\u001b[39m\u001b[34m(self, endpoint, data, json, **kwargs)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;129m@warn_outdated_sdk\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdo\u001b[39m():\n\u001b[32m    158\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._http.post(\n\u001b[32m    159\u001b[39m         \u001b[38;5;28mself\u001b[39m.api_gateway + endpoint,\n\u001b[32m    160\u001b[39m         data=data,\n\u001b[32m   (...)\u001b[39m\u001b[32m    163\u001b[39m         **kwargs,\n\u001b[32m    164\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdo\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/rl-learning/rft-grpo/.venv/lib/python3.11/site-packages/predibase/_client.py:218\u001b[39m, in \u001b[36m_to_json\u001b[39m\u001b[34m(resp)\u001b[39m\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    214\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBad request. Response status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Error: \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpayload.get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    215\u001b[39m     )\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m500\u001b[39m <= resp.status_code < \u001b[32m600\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m     payload = \u001b[43mpayload_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PredibaseServerError(\n\u001b[32m    220\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mServer error. Response status code \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Error: \u001b[39m\u001b[33m\"\u001b[39m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpayload.get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[33m'\u001b[39m\u001b[33mUnknown\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m    223\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m PredibaseResponseError(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected response code: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresp.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, resp.status_code)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/work/github/rl-learning/rft-grpo/.venv/lib/python3.11/site-packages/predibase/_client.py:240\u001b[39m, in \u001b[36mpayload_json\u001b[39m\u001b[34m(r)\u001b[39m\n\u001b[32m    237\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.exceptions.JSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m240\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PredibaseResponseError(\n\u001b[32m    241\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to decode payload as JSON. Response status code: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    242\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Raw payload text: \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mr.text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m    243\u001b[39m         r.status_code,\n\u001b[32m    244\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mPredibaseResponseError\u001b[39m: Failed to decode payload as JSON. Response status code: 500. Raw payload text: \n. Error: Expecting value: line 1 column 1 (char 0)\n"
     ]
    }
   ],
   "source": [
    "pb.finetuning.jobs.create(\n",
    "    config=GRPOConfig(\n",
    "        base_model=\"qwen2-5-7b-instruct\",\n",
    "        reward_fns=RewardFunctionsConfig(\n",
    "            runtime=RewardFunctionsRuntimeConfig(\n",
    "                packages=[\"pandas\"]\n",
    "            ),\n",
    "            functions={\n",
    "                \"output_format_check\": output_format_check,\n",
    "                \"uses_previous_feedback\": uses_previous_feedback,\n",
    "                \"guess_value\": guess_value,\n",
    "            }\n",
    "        ),\n",
    "        sampling_params=SamplingParamsConfig(max_tokens=4096),\n",
    "        num_generations=4\n",
    "    ),\n",
    "    dataset=dataset,\n",
    "    repo=\"wordle\",\n",
    "    description=\"Wordle GRPO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf8ef4-96cc-44e6-b6b9-382b4e3e0f28",
   "metadata": {},
   "source": [
    "The lecture just basically ends here - it doesn't include any code or specific examples of using the trained model. (It shows some graphs that they generated w/ this code.) I can come back and write my own code to use the model - likely building from what I did in previous lectures, like the one in lesson four, if I get to it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7821f-1f35-4b3a-8460-75096f8dcdc8",
   "metadata": {},
   "source": [
    "So, uploading the data seemed to perhaps not have worked - I think it should have taken at most a few mins, and it ran for 30m+ and judging from the Data UI on the Predibase site, is still running. I'll let it sit for a while and check again before calling it a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15606bd4-895b-4c1f-b90a-f34c7ecd5890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
