{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "746ff004-5ba9-4da9-bd92-ba1f72a6ed6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from predibase import (\n",
    "    Predibase,\n",
    "    GRPOConfig,\n",
    "    RewardFunctionsConfig,\n",
    "    RewardFunctionsRuntimeConfig,\n",
    "    SFTConfig,\n",
    "    SamplingParamsConfig,\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i think this is because the Predibase API sometimes gives warnings for version-related stuff (it does it in the course videos too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1216c8d1-2313-4f30-a948-4684c811d8f6",
   "metadata": {},
   "source": [
    "# Lesson eight: Actually do RFT via Predibase to train a model that plays Wordle, better"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49038118-c6e1-49de-8983-66e1c4a1660b",
   "metadata": {},
   "source": [
    "## First, train a fine-tuned model using RFT "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fad8ae30-68a8-43c2-b0b1-6fd518a7f570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Connected to Predibase as </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">f66dcd85</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-7638-4ead-9487-2506bb2c930b</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">username</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">aenfield</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">@gmail.com)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mConnected to Predibase as \u001b[0m\u001b[1;35mUser\u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;34m=\u001b[0m\u001b[93mf66dcd85\u001b[0m\u001b[93m-7638-4ead-9487-2506bb2c930b\u001b[0m\u001b[1;34m, \u001b[0m\u001b[1;33musername\u001b[0m\u001b[1;34m=\u001b[0m\u001b[1;35maenfield\u001b[0m\u001b[1;34m@gmail.com\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "_ = load_dotenv(override=True) # populate env from .env file, reload of file - 'override' - ok here\n",
    "\n",
    "pb = Predibase(api_token=os.environ['PREDIBASE_API_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57b5162-53ee-4128-89f8-06dac7416889",
   "metadata": {},
   "source": [
    "Load the training data that shows how to think about answers - they said this is from strong models like more expensive versions of Claude, but w/ the actual results/answers removed - I think to help train on the 'thinking' processes. They uploaded this data to HF, from where we'll get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95a8fa53-89e1-48cf-b69c-b502685f3564",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset('predibase/wordle-grpo', split='train')\n",
    "dataset = dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f64f73d5-e89f-4cac-85bc-e666717999d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# and now provide/upload the data to Predibase (I guess associated w/ my own account?)\n",
    "dataset_name = 'wordle-grpo-data-tryagain'\n",
    "\n",
    "try:\n",
    "    dataset = pb.datasets.from_pandas_dataframe(dataset, name=dataset_name)\n",
    "except Exception:\n",
    "    dataset = pb.datasets.get(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "903e2991-450d-41f0-98a2-3dffa3e3d7b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a Predibase 'repo' as the structure to collect what I'm doing\n",
    "repo = pb.repos.create(name='wordle', exists_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f74e75d-4b33-4353-b264-74ada9d6f241",
   "metadata": {},
   "source": [
    "The reward functions - more complicated than what we did in previous lessons, but still pretty straightforward. I got these from reward_functions.py."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d94c53f-d2c9-4ff9-bd58-c6940a28aefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_format_check(prompt: str, completion: str, example: dict) -> int:\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Check if the format matches expected pattern:\n",
    "        # <think> content </think> followed by <answer> content </answer>\n",
    "        regex = (\n",
    "            r\"^<think>\\s*([^<]*(?:<(?!/?think>)[^<]*)*)\\s*<\\/think>\\n\"\n",
    "            r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        )\n",
    "\n",
    "        # Search for the regex in the completion\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 2:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[1]\n",
    "        guess = guess.strip()\n",
    "\n",
    "        # If the word is not 5 characters, return 0\n",
    "        if len(guess) != 5:\n",
    "            return 0.1\n",
    "\n",
    "        # Check if the guess is a valid word compared to a predifined list of words\n",
    "        word_list = pd.read_csv(str(example[\"word_list\"]))\n",
    "        if guess not in word_list[\"Word\"].values:\n",
    "            return 0.5\n",
    "\n",
    "        reward = 1.0\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# Reward function that checks if the guess uses the previous feedback for its next guess\n",
    "def uses_previous_feedback(prompt: str, completion: str, example: dict) -> int:\n",
    "    import re\n",
    "    import ast\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Extract the guess from the completion\n",
    "        regex = r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 1:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[0].strip()\n",
    "        if len(guess) != 5:\n",
    "            return 0.0\n",
    "\n",
    "        past_guess_history = ast.literal_eval(example[\"past_guess_history\"])\n",
    "        if len(past_guess_history) == 0:\n",
    "            print(\"Uses previous feedback reward: 0.1 (No past guesses)\")\n",
    "            return 0.1\n",
    "\n",
    "        correct_letter_to_position = {}\n",
    "        valid_letter_to_position = {}\n",
    "        wrong_letter_to_position = {}\n",
    "        for _, past_feedback in past_guess_history:\n",
    "            past_feedback = past_feedback.split(\" \")\n",
    "            for i, fb in enumerate(past_feedback):\n",
    "                if '✓' in fb:\n",
    "                    if fb[0] not in correct_letter_to_position:\n",
    "                        correct_letter_to_position[fb[0]] = set()\n",
    "                    correct_letter_to_position[fb[0]].add(i)\n",
    "                elif '-' in fb:\n",
    "                    if fb[0] not in valid_letter_to_position:\n",
    "                        valid_letter_to_position[fb[0]] = set()\n",
    "                    valid_letter_to_position[fb[0]].add(i)\n",
    "                else:\n",
    "                    if fb[0] not in wrong_letter_to_position:\n",
    "                        wrong_letter_to_position[fb[0]] = set()\n",
    "                    wrong_letter_to_position[fb[0]].add(i)\n",
    "\n",
    "        for idx, letter in enumerate(guess):\n",
    "            # Positive reward if guess reuses letter in confirmed correct position\n",
    "            if (letter in correct_letter_to_position and idx in correct_letter_to_position[letter]):\n",
    "                reward += 0.2\n",
    "            # Reward if letter known to be in word is used in a new position\n",
    "            elif (letter in valid_letter_to_position and idx not in valid_letter_to_position[letter]):\n",
    "                reward += 0.1\n",
    "            # Penalize reuse of known-in-word letter in same position (not exploring)\n",
    "            elif (letter in valid_letter_to_position and idx in valid_letter_to_position[letter]):\n",
    "                reward -= 0.2\n",
    "            # Penalize use of known-absent letter\n",
    "            elif letter in wrong_letter_to_position:\n",
    "                reward -= 0.5\n",
    "            else:\n",
    "                # Reward unknown letters with partial credit for exploration\n",
    "                reward += 0.05\n",
    "\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "    return reward\n",
    "\n",
    "\n",
    "# Reward function that computes normalized information gain of the guess, i.e.,\n",
    "# does the new guess reduce the uncertainty of the secret word the most\n",
    "def guess_value(prompt: str, completion: str, example: dict) -> int:\n",
    "    import math\n",
    "    import re\n",
    "    import ast\n",
    "    import pandas as pd\n",
    "\n",
    "    def validate_guess(secret: str, guess: str, raw_feedback: bool = False) -> str:\n",
    "        feedback = []\n",
    "        secret_list = list(secret)\n",
    "\n",
    "        # Check for correct positions\n",
    "        for i, (g_char, s_char) in enumerate(zip(guess, secret)):\n",
    "            if g_char == s_char:\n",
    "                feedback.append(f\"{g_char}(✓) \")\n",
    "                secret_list[i] = None\n",
    "            else:\n",
    "                feedback.append(None)\n",
    "\n",
    "        # Check for misplaced letters\n",
    "        for i, g_char in enumerate(guess):\n",
    "            if feedback[i] is None:\n",
    "                if g_char in secret_list:\n",
    "                    feedback[i] = f\"{g_char}(-) \"\n",
    "                    secret_list[secret_list.index(g_char)] = None\n",
    "                else:\n",
    "                    feedback[i] = f\"{g_char}(x) \"\n",
    "\n",
    "        if raw_feedback:\n",
    "            return feedback\n",
    "        return \"\".join(feedback).strip()\n",
    "\n",
    "    def filter_candidates(all_candidate_words, past_guesses):\n",
    "        filtered = []\n",
    "        for word in all_candidate_words:\n",
    "            valid = True\n",
    "            for past_guess, past_feedback in past_guesses:\n",
    "                # Compute what the feedback would be if 'word' were the secret.\n",
    "                candidate_feedback = validate_guess(word, past_guess)\n",
    "                if candidate_feedback != past_feedback:\n",
    "                    valid = False\n",
    "                    break\n",
    "            if valid:\n",
    "                filtered.append(word)\n",
    "        return filtered\n",
    "\n",
    "    def compute_normalized_information_gain(all_candidate_words, past_guesses, guess):\n",
    "        # First, filter the candidate words based on past guesses.\n",
    "        candidates = filter_candidates(all_candidate_words, past_guesses)\n",
    "        total_candidates = len(candidates)\n",
    "\n",
    "        # If no candidates remain, return zeros.\n",
    "        if total_candidates == 0:\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        # Current uncertainty (entropy) before the guess.\n",
    "        current_entropy = math.log2(total_candidates)\n",
    "\n",
    "        # Partition candidates by the feedback pattern that would be produced by the current guess.\n",
    "        feedback_groups = {}\n",
    "        for word in candidates:\n",
    "            # Get the raw feedback list (e.g., ['B(✓) ', 'R(✓) ', 'A(x) ', ...])\n",
    "            feedback = validate_guess(word, guess, raw_feedback=True)\n",
    "            # Create a simple representation for the feedback pattern.\n",
    "            # '1' for correct position, '0' for wrong position, 'x' for letter not in word.\n",
    "            feedback_pattern = \"\".join('1' if \"✓\" in fb else ('0' if \"-\" in fb else 'x') \n",
    "                                    for fb in feedback)\n",
    "            feedback_groups.setdefault(feedback_pattern, []).append(word)\n",
    "\n",
    "        expected_entropy = 0\n",
    "        max_info_gain = 0\n",
    "        # For each feedback group, compute its contribution to the expected entropy and the info gain.\n",
    "        for group in feedback_groups.values():\n",
    "            group_size = len(group)\n",
    "            p = group_size / total_candidates\n",
    "            # Entropy if this feedback is received.\n",
    "            group_entropy = math.log2(group_size) if group_size > 0 else 0\n",
    "            expected_entropy += p * group_entropy\n",
    "            # Information gain for this feedback outcome.\n",
    "            info_gain = current_entropy - group_entropy\n",
    "            max_info_gain = max(max_info_gain, info_gain)\n",
    "\n",
    "        # The expected gain is the reduction in entropy on average.\n",
    "        expected_gain = current_entropy - expected_entropy\n",
    "\n",
    "        # Normalize by the maximum possible gain, which is current_entropy (if you reduced to one candidate).\n",
    "        normalized_expected_gain = expected_gain / current_entropy if current_entropy > 0 else 0\n",
    "        normalized_max_gain = max_info_gain / current_entropy if current_entropy > 0 else 0\n",
    "\n",
    "        return normalized_expected_gain, normalized_max_gain\n",
    "\n",
    "    reward = 0\n",
    "    try:\n",
    "        # Add synthetic <think> as it's already part of the prompt and prefilled \n",
    "        # for the assistant to more easily match the regex\n",
    "        completion = \"<think>\" + completion\n",
    "\n",
    "        # Extract the guess from the completion\n",
    "        regex = r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>$\"\n",
    "        match = re.search(regex, completion, re.DOTALL)\n",
    "        if match is None or len(match.groups()) != 1:\n",
    "            return 0\n",
    "\n",
    "        guess = match.groups()[0].strip()\n",
    "        if len(guess) != 5:\n",
    "            return 0.0\n",
    "\n",
    "        # Load the word list\n",
    "        word_list = pd.read_csv(str(example[\"word_list\"]))\n",
    "        if guess not in word_list[\"Word\"].values:\n",
    "            return 0.0\n",
    "\n",
    "        # Extract past guesses and feedback\n",
    "        past_guess_history = ast.literal_eval(example[\"past_guess_history\"])\n",
    "\n",
    "        # Compute normalized information gain\n",
    "        normalized_expected_gain, _ = compute_normalized_information_gain(\n",
    "            word_list[\"Word\"].values,\n",
    "            past_guess_history,\n",
    "            guess\n",
    "        )\n",
    "\n",
    "        # Compute reward based on normalized information gain\n",
    "        reward = normalized_expected_gain\n",
    "    except Exception:\n",
    "        return 0.0\n",
    "\n",
    "    return reward\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886a5d15-95e6-4689-80e3-1be06e99ccb9",
   "metadata": {},
   "source": [
    "And, ok, I should be able to actually train the updated model w/ just one call. The only things I need to provide are the base model's name, to specify the reward functions (the three functions just above), give a few config params, and the dataset on which to train (the one I uploaded above). Then Predibase just goes to town, apparently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "498776d4-8f78-4218-9b2f-5bd1c6c6b0ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully requested finetuning of qwen2-5-7b-instruct from base as `wordle/1`. (Job UUID: 91feeade-8a29-431c-ab6a-a83b4a64021e).\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FinetuningJob(uuid='91feeade-8a29-431c-ab6a-a83b4a64021e', base_model='qwen2-5-7b-instruct', dataset='wordle-grpo-data-tryagain', description='Wordle GRPO', target_repo='wordle', target_version_tag=1, accelerator='', status='pending', params=GRPOConfig(base_model='qwen2-5-7b-instruct', adapter='lora', task='grpo', epochs=None, learning_rate=None, rank=None, target_modules=None, enable_early_stopping=None, apply_chat_template=None, lr_scheduler=None, optimizer=None, lora_alpha=None, lora_dropout=None, warmup_ratio=None, effective_batch_size=None, beta=None, num_generations=4, sampling_params=SamplingParamsConfig(temperature=None, top_p=None, top_k=None, max_tokens=4096), reward_fns=RewardFunctionsConfig(runtime=RewardFunctionsRuntimeConfig(packages=['pandas']), functions={'guess_value': RewardFunction(encoded_fn='ZGVmIGd1ZXNzX3ZhbHVlKHByb21wdD...'), 'output_format_check': RewardFunction(encoded_fn='ZGVmIG91dHB1dF9mb3JtYXRfY2hlY2...'), 'uses_previous_feedback': RewardFunction(encoded_fn='ZGVmIHVzZXNfcHJldmlvdXNfZmVlZG...')})))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pb.finetuning.jobs.create(\n",
    "    config=GRPOConfig(\n",
    "        base_model=\"qwen2-5-7b-instruct\",\n",
    "        reward_fns=RewardFunctionsConfig(\n",
    "            runtime=RewardFunctionsRuntimeConfig(\n",
    "                packages=[\"pandas\"]\n",
    "            ),\n",
    "            functions={\n",
    "                \"output_format_check\": output_format_check,\n",
    "                \"uses_previous_feedback\": uses_previous_feedback,\n",
    "                \"guess_value\": guess_value,\n",
    "            }\n",
    "        ),\n",
    "        sampling_params=SamplingParamsConfig(max_tokens=4096),\n",
    "        num_generations=4\n",
    "    ),\n",
    "    dataset=dataset,\n",
    "    repo=\"wordle\",\n",
    "    description=\"Wordle GRPO\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9cf8ef4-96cc-44e6-b6b9-382b4e3e0f28",
   "metadata": {},
   "source": [
    "The lecture just basically ends here - it doesn't include any code or specific examples of using the trained model. (It shows some graphs that they generated w/ this code.) I came back as below and wrote my own code/used the code from lesson three to actually use the fine-tuned model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc7821f-1f35-4b3a-8460-75096f8dcdc8",
   "metadata": {},
   "source": [
    "So, uploading the data didn't work the first time - I think it should have taken at most a few mins, and it ran for 30m+ and judging from the Data UI on the Predibase site, is still running. I let it sit for a while and checked again before calling it a day - it actually ran for more than 24 hours. I contacted support, and they got back to me w/i that day and said they'd fixed the problem. I tried it myself and it succeeded, in less than a minute."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa08efce-76e3-46e5-905a-76d0a746c778",
   "metadata": {},
   "source": [
    "Then, I ran the above code to do a training run and build a fine-tuned model. After ~30m of queuing time, Predibase started training. I let it run for ~3.5 hours on the default A100 hardware and got 237 training steps, of the 1000 that is the default for GRPOConfig. Then I stopped it, as that much of a run had cost ~$20 for the 1.85M tokens the training process had used (at the $10/1M tokens that Predibase charges for this kind of fine tuning) and so I'd used most of the $25 in free credits Predibase provides. I stopped it using the web UI. \n",
    "\n",
    "I didn't know if the resulting model would be usable, but it does at least run without giving me errors, as the text below shows. It doesn't do particularly well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0b3030-217e-42c5-85bb-f63562e06c67",
   "metadata": {},
   "source": [
    "## Then use the fine-tuned model to play Wordle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c700807-07a1-474c-bdd5-e4a1bbe3edd7",
   "metadata": {},
   "source": [
    "I use the code from lesson three - in that lecture the code uses a non-fine-tuned model - a base Qwen model - to play Wordle. Here I instead used the fine-tuned model that I trained above. \n",
    "\n",
    "This runs, so that's good. However, it's not great - for example, it looks like it doesn't take understand feedback that tells it a letter is correct but in the wrong position. I don't know if this is something that's a result of me stopping the fine-tuning before it ran its specified number of steps, or if there's another issue. For now, I won't worry about spending more or digging deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c180d90a-fb0e-4631-b07a-3afb9c96ab5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(override=True) # populate env from .env file, reload of file - 'override' - ok here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bd765067-6055-47b1-8210-15333cd02c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI # lesson 3 uses OpenAI completions code, but with a base URL on the Predibase site, as below\n",
    "\n",
    "# Predibase provides a OpenAI chat completions v1 endpoint, which is what the tutorial uses\n",
    "# the model URL changes by user and I've created my own based on docs at https://docs.predibase.com/user-guide/inference/migrate-openai\n",
    "client = OpenAI(\n",
    "    base_url=os.environ['PREDIBASE_QWEN_MODEL_URL'], \n",
    "    api_key=os.environ['PREDIBASE_API_TOKEN'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "58c5af60-6bac-4b9d-bcc9-3c24879ad979",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_id = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a2d24c94-ecec-4ed0-9e5e-453ad77ee340",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are playing Wordle, a word-guessing game.\n",
    "\n",
    "### Game Rules:\n",
    "- You have **6 tries** to guess a secret **5-letter** word.\n",
    "- Each guess must be a valid **5-letter English word**.\n",
    "- After each guess, you will receive feedback indicating how close \n",
    "your guess was.\n",
    "\n",
    "### Feedback Format:\n",
    "Each letter in your guess will receive one of three symbols:\n",
    "1. ✓ : The letter is in the word and in the CORRECT position.\n",
    "2. - : The letter is in the word but in the WRONG position.\n",
    "3. x : The letter is NOT in the word.\n",
    "\n",
    "### Example:\n",
    "Secret Word: BRISK\n",
    "\n",
    "Guess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\n",
    "Guess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\n",
    "Guess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\n",
    "\n",
    "### Response Format:\n",
    "Think through the problem and feedback step by step. Make sure to \n",
    "first add your step-by-step thought process within <think> </think> \n",
    "tags. Then, return your guessed word in the following format: \n",
    "<guess> guessed-word </guess>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca65982b-cbfd-426f-b23d-bd102c6afc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "class LetterFeedback(Enum):\n",
    "    CORRECT = \"✓\"\n",
    "    WRONG_POS = \"-\"\n",
    "    WRONG_LETTER = \"x\"\n",
    "\n",
    "@dataclass\n",
    "class GuessWithFeedback:\n",
    "    guess: str\n",
    "    feedback: List[LetterFeedback]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"A human (and LLM)-readable string showing the guess and letter-by-letter feedback\"\n",
    "        feedback_str = \" \".join(f\"{letter}({fb.value})\" for letter, fb in zip(self.guess, self.feedback))\n",
    "        return f\"{self.guess} -> Feedback: {feedback_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea59e653-f7cd-4a60-8a43-2c5887010de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_user_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    \"Creates a user-facing prompt that includes past guesses and the matching feedback.\"\n",
    "    prompt = \"Make a new 5-letter word guess.\"\n",
    "    if past_guesses:\n",
    "        prompt += \"\\n\\nHere is some previous feedback:\"\n",
    "        for i, guess in enumerate(past_guesses):\n",
    "            prompt += f\"\\nGuess {i+1}: {guess}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e72542c2-126f-4abb-b4e4-350958b52474",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    \"\"\"Formats a full chat prompt using a system message, user prompt, and assistant \n",
    "    preamble to start the model's step-by-step reasoning.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": render_user_prompt(past_guesses)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, continue_final_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ecfeaa4e-a5df-4108-8fb5-8a962e9afaf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream(prompt: str, adapter_id: str = \"\") -> str:\n",
    "    \"Streams a model-generated response from a prompt in real time, printing as tokens arrive.\"\n",
    "    response = client.completions.create(\n",
    "        model=adapter_id,\n",
    "        prompt=prompt,\n",
    "        temperature=0.0, # deterministic, for evaluation\n",
    "        max_tokens=2048,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    completion = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].text is not None:\n",
    "            content = chunk.choices[0].text\n",
    "            print(content, end=\"\", flush=True)\n",
    "            completion += content\n",
    "    print\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c85b80-7bbf-4c83-8379-5367be5bc697",
   "metadata": {},
   "source": [
    "And check that I can use the above code to get one response, from the fine-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a5d46278-9a34-4ab7-b603-336680fdbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "You are playing Wordle, a word-guessing game.\n",
      "\n",
      "### Game Rules:\n",
      "- You have **6 tries** to guess a secret **5-letter** word.\n",
      "- Each guess must be a valid **5-letter English word**.\n",
      "- After each guess, you will receive feedback indicating how close \n",
      "your guess was.\n",
      "\n",
      "### Feedback Format:\n",
      "Each letter in your guess will receive one of three symbols:\n",
      "1. ✓ : The letter is in the word and in the CORRECT position.\n",
      "2. - : The letter is in the word but in the WRONG position.\n",
      "3. x : The letter is NOT in the word.\n",
      "\n",
      "### Example:\n",
      "Secret Word: BRISK\n",
      "\n",
      "Guess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\n",
      "Guess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\n",
      "Guess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\n",
      "\n",
      "### Response Format:\n",
      "Think through the problem and feedback step by step. Make sure to \n",
      "first add your step-by-step thought process within <think> </think> \n",
      "tags. Then, return your guessed word in the following format: \n",
      "<guess> guessed-word </guess>.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Make a new 5-letter word guess.\n",
      "\n",
      "Here is some previous feedback:\n",
      "Guess 1: CRANE -> Feedback: C(✓) R(✓) A(✓) N(x) E(x)\n",
      "Guess 2: CRASH -> Feedback: C(✓) R(✓) A(✓) S(x) H(x)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "secret_word = \"CRAFT\"\n",
    "\n",
    "past_guesses = [\n",
    "    GuessWithFeedback(\n",
    "        \"CRANE\", [\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "    GuessWithFeedback(\n",
    "        \"CRASH\", [\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "]\n",
    "\n",
    "prompt = render_prompt(past_guesses)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fefc4020-a865-40b4-8a79-9090e2e593d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "- From Guess 1 (CRANE), we know that C, R, and A are correct letters in the word.\n",
      "- From Guess 2 (CRASH), we can confirm C and R are correct, but they are in the right positions as well.\n",
      "- The letter A is also correct and in the right position.\n",
      "- N and E from CRANE are not in the word.\n",
      "- S and H from CRASH are not in the word.\n",
      "- This leaves us with the letters B, D, G, I, L, M, P, T, U, V, W, X, Y, Z to choose from for our next guess.\n",
      "- We need to include C, R, and A in our next guess and avoid S, H, N, E.\n",
      "</think>\n",
      "<guess> BRICK </guess>"
     ]
    }
   ],
   "source": [
    "finetuned_adapter_id = 'wordle/1'\n",
    "\n",
    "ft_completion = generate_stream(prompt, adapter_id=finetuned_adapter_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00bcc7d-1fe4-433b-ae29-ef30b14ba5ef",
   "metadata": {},
   "source": [
    "And then add in the code, again from lesson three, to play a full game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1eacdd89-ccb7-4b4d-87c6-254ddb9cd29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_feedback(guess: str, secret_word: str) -> List[LetterFeedback]:\n",
    "    \"Generate a list of tripartite feedback for each letter of the guess.\"\n",
    "    valid_letters = set(secret_word)\n",
    "    feedback = []\n",
    "    for letter, secret_letter in zip(guess, secret_word):\n",
    "        if letter == secret_letter:\n",
    "            feedback.append(LetterFeedback.CORRECT)\n",
    "        elif letter in valid_letters:\n",
    "            feedback.append(LetterFeedback.WRONG_POS)\n",
    "        else:\n",
    "            feedback.append(LetterFeedback.WRONG_LETTER)\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e00c9bd6-74b6-43c6-9e05-e68219325d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_turn(\n",
    "    past_guesses: List[GuessWithFeedback],\n",
    "    secret_word: str,\n",
    "    adapter_id = \"\"\n",
    "):\n",
    "    \"\"\"Do a full turn: build a prompt incorporating previous guesses, \n",
    "    use the LLM to get a new guess, and check and score it.\"\"\"\n",
    "    prompt = render_prompt(past_guesses)\n",
    "    completion = generate_stream(prompt, adapter_id)\n",
    "    \n",
    "    match = re.search(r\"<guess>\\s*(.*?)\\s*</guess>\", completion, re.DOTALL)\n",
    "    if not match:\n",
    "        print(completion)\n",
    "        raise RuntimeError(\"Invalid guess - no guess found in response.\")\n",
    "    guess = match.group(1).upper()\n",
    "    \n",
    "    feedback = get_feedback(guess, secret_word)\n",
    "    past_guesses.append(GuessWithFeedback(guess, feedback))\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print((\"-\" * 100) + \"\\n\")\n",
    "    for past_guess in past_guesses:\n",
    "        print(past_guess)\n",
    "\n",
    "    if guess == secret_word:\n",
    "        print(\"SUCCESS - win\")\n",
    "    elif len(past_guesses) >= 6:\n",
    "        print(\"LOSS - ran out of guesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "35e4b118-1b52-4051-bb1b-d8abbd116feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_word = \"BRICK\"\n",
    "past_guesses = []\n",
    "\n",
    "adapter_id = finetuned_adapter_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5849da39-e235-4404-a600-599cc8d234da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Considering the rules and feedback format, I need to make an initial guess that covers a wide range of letters. A common starting word is \"CRANE\" as it includes vowels and consonants which are frequently used in English words.</think>\n",
      "<guess> CRANE </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(-) R(✓) A(x) N(x) E(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "49d21e0e-1220-4edc-90f9-7269f7283f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Given the feedback from the first guess, we know:\n",
      "- R is in the correct position (3rd letter).\n",
      "- C, A, N, and E are not part of the word.\n",
      "The possible letters are now limited to the ones not mentioned (B, D, F, G, H, I, J, K, L, M, P, Q, S, T, U, V, W, X, Y, Z).\n",
      "\n",
      "Since R is already placed correctly, we need to find a new combination of letters that fits the criteria.\n",
      "Considering common 5-letter words, let's try a word that includes R and avoids C, A, N, and E.</think>\n",
      "<guess> STRAP </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(-) R(✓) A(x) N(x) E(x)\n",
      "STRAP -> Feedback: S(x) T(x) R(-) A(x) P(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "827b8c84-c552-4897-b816-709bafa94407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "From Guess 1 (CRANE):\n",
      "- R is correct and in the right position (✓).\n",
      "- C, A, N, and E are not in the word.\n",
      "\n",
      "From Guess 2 (STRAP):\n",
      "- A is correct and in the right position (✓).\n",
      "- S, T, R, and P are not in the word.\n",
      "\n",
      "The word must contain R and A. It cannot contain C, N, E, S, T, or P.\n",
      "</think>\n",
      "<guess> BRICK </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(-) R(✓) A(x) N(x) E(x)\n",
      "STRAP -> Feedback: S(x) T(x) R(-) A(x) P(x)\n",
      "BRICK -> Feedback: B(✓) R(✓) I(✓) C(✓) K(✓)\n",
      "SUCCESS - win\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b990f7b-0966-478d-9379-59fdb3344f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Since this is the first guess, I'll choose a common 5-letter word that has a mix of vowels and consonants to maximize the chances of getting some correct positions or letters. A good starting word could be \"CRANE\".\n",
      "</think>\n",
      "<guess> CRANE </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n"
     ]
    }
   ],
   "source": [
    "secret_word = \"SALES\"\n",
    "past_guesses = []\n",
    "\n",
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6b1314f8-d95e-4a09-9706-afdb9be4c327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Given the feedback from the first guess, none of the letters C, R, A, N, or E appear in the secret word. This means we need to choose a completely different set of letters for our next guess. I'll consider common 5-letter words that don't include these letters. A good choice could be a word like \"FLUTE\" which is a common English word.</think>\n",
      "<guess> FLUTE </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
      "FLUTE -> Feedback: F(x) L(-) U(x) T(x) E(-)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "634f2e7a-6c7e-45db-963e-129560c1c6f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " From the feedback, we know that none of the letters in CRANE or FLUTE are correct. This means we need to choose a completely different set of letters for our next guess.\n",
      "I'll consider common 5-letter words that don't include any of these letters (C, R, A, N, E, F, L, U). Some good options could be words like 'SWAMP', 'BREAD', 'GHOST', etc.\n",
      "I'll go with 'SWAMP' as it's a common 5-letter word and doesn't include any of the disallowed letters.</think>\n",
      "<guess> SWAMP </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
      "FLUTE -> Feedback: F(x) L(-) U(x) T(x) E(-)\n",
      "SWAMP -> Feedback: S(✓) W(x) A(-) M(x) P(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0d6be171-333b-47eb-bc5e-0bdf8c83c8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "From the feedback:\n",
      "- Guess 1 (CRANE): No letters are correct.\n",
      "- Guess 2 (FLUTE): Only 'T' is correct.\n",
      "- Guess 3 (SWAMP): 'S' is correct.\n",
      "\n",
      "The word must contain 'S' and 'T'. Let's try to form a new word that includes these letters and avoids the incorrect ones from previous guesses.\n",
      "</think>\n",
      "<guess> STAND </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
      "FLUTE -> Feedback: F(x) L(-) U(x) T(x) E(-)\n",
      "SWAMP -> Feedback: S(✓) W(x) A(-) M(x) P(x)\n",
      "STAND -> Feedback: S(✓) T(x) A(-) N(x) D(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "11bc5e53-da1c-4f33-9aa8-cf3fd7dbde67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "From the feedback:\n",
      "- Guess 1 (CRANE): No letters are correct.\n",
      "- Guess 2 (FLUTE): Only 'T' is correct.\n",
      "- Guess 3 (SWAMP): 'S' is correct.\n",
      "- Guess 4 (STAND): 'S' is correct.\n",
      "\n",
      "The word must contain 'S' and no other letters from these guesses can be used again. The remaining letters are A, C, E, F, L, M, N, P, R, W, and T. \n",
      "\n",
      "Since 'S' is already confirmed, we need to avoid using any of the letters from the previous guesses that were incorrect or not in the right place. This leaves us with A, C, E, F, L, M, N, P, R, W, and T.\n",
      "\n",
      "Let's try a new word that includes 'S' and avoids the letters from the previous guesses.\n",
      "</think>\n",
      "<guess> SMILE </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
      "FLUTE -> Feedback: F(x) L(-) U(x) T(x) E(-)\n",
      "SWAMP -> Feedback: S(✓) W(x) A(-) M(x) P(x)\n",
      "STAND -> Feedback: S(✓) T(x) A(-) N(x) D(x)\n",
      "SMILE -> Feedback: S(✓) M(x) I(x) L(-) E(-)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a18c42a-2c0f-45fa-935f-739a12ff68bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "- From guess 1 (CRANE), we know that none of the letters C, R, A, N, E are in the correct positions.\n",
      "- From guess 2 (FLUTE), we know that none of the letters F, L, U are in the correct positions.\n",
      "- From guess 3 (SWAMP), we know that S is in the first position, and W, A, M, P are not in the correct positions.\n",
      "- From guess 4 (STAND), we know that S is in the first position, and T, A, N, D are not in the correct positions.\n",
      "- From guess 5 (SMILE), we know that S is in the first position, and M, I, L, E are not in the correct positions.\n",
      "\n",
      "Combining all this information, we can deduce that the first letter must be S. The second letter cannot be T, A, N, D, or E, so it could be any other letter. The third letter cannot be A, M, P, I, L, E, so it could be any other letter. The fourth letter cannot be T, A, N, D, or E, so it could be any other letter. The fifth letter cannot be M, I, L, E, so it could be any other letter.\n",
      "\n",
      "A good guess would be a word starting with S, containing no repeated letters from the previous guesses, and checking for common 5-letter words.\n",
      "</think>\n",
      "<guess> SPARK </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(x) R(x) A(-) N(x) E(-)\n",
      "FLUTE -> Feedback: F(x) L(-) U(x) T(x) E(-)\n",
      "SWAMP -> Feedback: S(✓) W(x) A(-) M(x) P(x)\n",
      "STAND -> Feedback: S(✓) T(x) A(-) N(x) D(x)\n",
      "SMILE -> Feedback: S(✓) M(x) I(x) L(-) E(-)\n",
      "SPARK -> Feedback: S(✓) P(x) A(-) R(x) K(x)\n",
      "LOSS - ran out of guesses\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887e21c4-9de4-4fa8-8ecc-2c918a260252",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
