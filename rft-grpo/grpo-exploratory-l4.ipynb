{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8e2cefc0-580f-4b03-a27e-5eff4c405f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from predibase import Predibase, DeploymentConfig\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "from transformers import AutoTokenizer\n",
    "import re\n",
    "from tabulate import tabulate\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from typing import List\n",
    "from enum import Enum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i think this is because the Predibase API sometimes gives warnings for version-related stuff (it does it in the course videos too)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a51e06-e5c4-4af5-b2bf-265a6a51111a",
   "metadata": {},
   "source": [
    "# Lesson four: Reward functions for Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36dc5658-a6d1-43ce-a17f-e40b4635093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_id = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "private_deployment_name = 'qwen2-5-7b-instruct-dlai'\n",
    "\n",
    "_ = load_dotenv(override=True) # populate env from .env file, reload of file - 'override' - ok here\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9030412f-9816-432a-8a42-54f814c74b57",
   "metadata": {},
   "source": [
    "## Set up stuff from the previous lectures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cc6352-bfce-4de2-834c-311854d2871b",
   "metadata": {},
   "source": [
    "I could just load from utils.py, but I'd like the functions here so I can see them w/o one extra trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5d2ab75f-b957-4b4a-8e15-7d7505ff1a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are playing Wordle, a word-guessing game.\n",
    "\n",
    "### Game Rules:\n",
    "- You have **6 tries** to guess a secret **5-letter** word.\n",
    "- Each guess must be a valid **5-letter English word**.\n",
    "- After each guess, you will receive feedback indicating how close your guess was.\n",
    "\n",
    "### Feedback Format:\n",
    "Each letter in your guess will receive one of three symbols:\n",
    "1. âœ“ : The letter is in the word and in the CORRECT position.\n",
    "2. - : The letter is in the word but in the WRONG position.\n",
    "3. x : The letter is NOT in the word.\n",
    "\n",
    "### Example:\n",
    "Secret Word: BRISK\n",
    "\n",
    "Guess 1: STORM â†’ Feedback: S(-) T(x) O(x) R(-) M(x)\n",
    "Guess 2: BRAVE â†’ Feedback: B(âœ“) R(âœ“) A(x) V(x) E(x)\n",
    "Guess 3: BRISK â†’ Feedback: B(âœ“) R(âœ“) I(âœ“) S(âœ“) K(âœ“)\n",
    "\n",
    "### Response Format:\n",
    "Think through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8acd4448-12fc-489b-8a13-69e81256426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LetterFeedback(Enum):\n",
    "    CORRECT = \"âœ“\"\n",
    "    WRONG_POS = \"-\"\n",
    "    WRONG_LETTER = \"x\"\n",
    "\n",
    "def get_feedback(guess: str, secret_word: str) -> List[LetterFeedback]:\n",
    "    valid_letters = set(secret_word)\n",
    "    feedback = []\n",
    "    for letter, secret_letter in zip(guess, secret_word):\n",
    "        if letter == secret_letter:\n",
    "            feedback.append(LetterFeedback.CORRECT)\n",
    "        elif letter in valid_letters:\n",
    "            feedback.append(LetterFeedback.WRONG_POS)\n",
    "        else:\n",
    "            feedback.append(LetterFeedback.WRONG_LETTER)\n",
    "    return feedback\n",
    "\n",
    "@dataclass\n",
    "class GuessWithFeedback:\n",
    "    guess: str\n",
    "    feedback: List[LetterFeedback]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        feedback_str = \" \".join(f\"{letter}({fb.value})\" for letter, fb in zip(self.guess, self.feedback))\n",
    "        return f\"{self.guess} â†’ Feedback: {feedback_str}\"\n",
    "\n",
    "    @staticmethod\n",
    "    def from_secret(guess: str, secret: str) -> \"GuessWithFeedback\":\n",
    "        return GuessWithFeedback(guess, get_feedback(guess, secret))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d926cf6c-4a2c-43d0-bf07-bc646612add2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_user_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    prompt = \"Make a new 5-letter word guess.\"\n",
    "    if past_guesses:\n",
    "        prompt += \"\\n\\nHere is some previous feedback:\"\n",
    "        for i, guess in enumerate(past_guesses):\n",
    "            prompt += f\"\\nGuess {i+1}: {guess}\"\n",
    "    return prompt\n",
    "\n",
    "def get_messages(past_guesses: List[GuessWithFeedback]):\n",
    "    return [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": render_user_prompt(past_guesses)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "def render_prompt(past_guesses: List[GuessWithFeedback]):\n",
    "    messages = get_messages(past_guesses)\n",
    "    return tokenizer.apply_chat_template(\n",
    "        messages, tokenize=False, continue_final_message=True\n",
    "    )\n",
    "\n",
    "def extract_guess(completion: str) -> str:\n",
    "    match = re.search(r\"<guess>\\s*([\\s\\S]*?)\\s*<\\/guess>\", completion, re.DOTALL)\n",
    "    if not match:\n",
    "        return \"\"\n",
    "    return match.group(1).strip().upper()\n",
    "\n",
    "def next_turn(past_guesses: List[GuessWithFeedback], secret_word: str, adapter_id = \"\"):\n",
    "    prompt = render_prompt(past_guesses)\n",
    "    completion = generate_stream(prompt)\n",
    "    guess = extract_guess(completion)\n",
    "\n",
    "    feedback = get_feedback(guess, secret_word)\n",
    "    past_guesses.append(GuessWithFeedback(guess, feedback))\n",
    "    print(\"\\n\\n\")\n",
    "    print((\"-\" * 100) + \"\\n\")\n",
    "    for past_guess in past_guesses:\n",
    "        print(past_guess)\n",
    "\n",
    "    if guess == secret_word:\n",
    "        print(\"ðŸŽ‰ SUCCESS ðŸŽ‰\")\n",
    "    elif len(past_guesses) >= 6:\n",
    "        print(\"âŒ better luck next time... âŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e9051f8-113e-46f0-a252-8053bc45be57",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_of_client = OpenAI(\n",
    "    base_url=os.environ[\"PREDIBASE_QWEN_MODEL_URL\"],\n",
    "    api_key=os.environ[\"PREDIBASE_API_TOKEN\"],\n",
    ")\n",
    "\n",
    "def generate(\n",
    "    messages: List[dict],\n",
    "    adapter_id: str = \"\",\n",
    "    num_guesses: int = 1,\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 1024,\n",
    ") -> List[str]:\n",
    "    if temperature > 0.0:\n",
    "        completions = best_of_client.chat.completions.create(\n",
    "            model=adapter_id,\n",
    "            messages=messages,\n",
    "            n=num_guesses,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return [choice.message.content for choice in completions.choices]\n",
    "    else:\n",
    "        return [\n",
    "            best_of_client.chat.completions.create(\n",
    "                model=adapter_id,\n",
    "                messages=messages,\n",
    "                n=1,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            ).choices[0].message.content for _ in range(num_guesses)\n",
    "        ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d70aef-8113-49bd-a916-12fa245aab2d",
   "metadata": {},
   "source": [
    "## Create private deployment, if it doesn't exist already"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7100a6eb-e677-4960-abce-e78570cb1e50",
   "metadata": {},
   "source": [
    "Create a custom deployed instance of the Qwen 2.5 7B instruct model, using Predibase's API, which we'll start using for inference here and then fine-tune - using Predibase's API - below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "034b3712-7654-422f-9850-85c154840912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Connected to Predibase as </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">f66dcd85</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-7638-4ead-9487-2506bb2c930b</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">username</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">aenfield</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">@gmail.com)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mConnected to Predibase as \u001b[0m\u001b[1;35mUser\u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;34m=\u001b[0m\u001b[93mf66dcd85\u001b[0m\u001b[93m-7638-4ead-9487-2506bb2c930b\u001b[0m\u001b[1;34m, \u001b[0m\u001b[1;33musername\u001b[0m\u001b[1;34m=\u001b[0m\u001b[1;35maenfield\u001b[0m\u001b[1;34m@gmail.com\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deployment qwen2-5-7b-instruct-dlai already exists\n"
     ]
    }
   ],
   "source": [
    "def create_deployment(name: str):\n",
    "    \"Creates Predibase 'deployment' per utils.py, needed since I'm running this locally and can't use the one they've created, I think.\"\n",
    "    pb = Predibase(api_token=os.environ[\"PREDIBASE_API_TOKEN\"])\n",
    "    try:\n",
    "        pb.deployments.create(\n",
    "            name=name,\n",
    "            config=DeploymentConfig(\n",
    "                accelerator='a10_24gb_100', # cheapest ($2.60/hr), I added this to the code from utils.py, thinking I'd avoid it 'helpfully' picking a more expensive option \n",
    "                base_model=\"qwen2-5-7b-instruct\",\n",
    "                min_replicas=0,\n",
    "                max_replicas=1,\n",
    "                cooldown_time=1200,\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        print(f\"Deployment {name} already exists\")\n",
    "\n",
    "create_deployment(private_deployment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765c0e87-9a15-4585-8f91-ef0be49a667f",
   "metadata": {},
   "source": [
    "## Start with a simple reward function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a3d17c-79ab-42bf-8177-1eebce1a3185",
   "metadata": {},
   "source": [
    "First, I'll try a simple 0/1 reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "277863fe-5e84-4221-8418-dd05ebec16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordle_reward(guess: str, secret_word: str) -> int:\n",
    "    if guess.upper() == secret_word.upper():\n",
    "        return 1 # correct\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "436eb399-bc54-4e59-bbe6-9e2bd0f3370d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[CRANE â†’ Feedback: C(x) R(x) A(x) N(âœ“) E(x),\n",
       " BLOND â†’ Feedback: B(x) L(x) O(-) N(âœ“) D(âœ“),\n",
       " FOUND â†’ Feedback: F(x) O(âœ“) U(âœ“) N(âœ“) D(âœ“)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "secret_word = \"POUND\"\n",
    "\n",
    "past_guesses = [\n",
    "    GuessWithFeedback.from_secret(guess=\"CRANE\", secret=secret_word),\n",
    "    GuessWithFeedback.from_secret(guess=\"BLOND\", secret=secret_word),\n",
    "    GuessWithFeedback.from_secret(guess=\"FOUND\", secret=secret_word),\n",
    "]\n",
    "past_guesses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188500da-1cbc-4b69-8aa6-f17042aa7a7e",
   "metadata": {},
   "source": [
    "Build a prompt including the feedback from the previous guesses and then send it to the LLM to have it think and generate a response.\n",
    "\n",
    "NOTE: As of the beginning of the lecture, this isn't using the custom deployment, I'm pretty sure - it's using the shared Qwen model, due to the way 'best_of_client' is created using the chat.completions API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "044c82ae-8de1-4262-8ee1-32a70cf43081",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system',\n",
       "  'content': '\\nYou are playing Wordle, a word-guessing game.\\n\\n### Game Rules:\\n- You have **6 tries** to guess a secret **5-letter** word.\\n- Each guess must be a valid **5-letter English word**.\\n- After each guess, you will receive feedback indicating how close your guess was.\\n\\n### Feedback Format:\\nEach letter in your guess will receive one of three symbols:\\n1. âœ“ : The letter is in the word and in the CORRECT position.\\n2. - : The letter is in the word but in the WRONG position.\\n3. x : The letter is NOT in the word.\\n\\n### Example:\\nSecret Word: BRISK\\n\\nGuess 1: STORM â†’ Feedback: S(-) T(x) O(x) R(-) M(x)\\nGuess 2: BRAVE â†’ Feedback: B(âœ“) R(âœ“) A(x) V(x) E(x)\\nGuess 3: BRISK â†’ Feedback: B(âœ“) R(âœ“) I(âœ“) S(âœ“) K(âœ“)\\n\\n### Response Format:\\nThink through the problem and feedback step by step. Make sure to first add your step by step thought process within <think> </think> tags. Then, return your guessed word in the following format: <guess> guessed-word </guess>.\\n'},\n",
       " {'role': 'user',\n",
       "  'content': 'Make a new 5-letter word guess.\\n\\nHere is some previous feedback:\\nGuess 1: CRANE â†’ Feedback: C(x) R(x) A(x) N(âœ“) E(x)\\nGuess 2: BLOND â†’ Feedback: B(x) L(x) O(-) N(âœ“) D(âœ“)\\nGuess 3: FOUND â†’ Feedback: F(x) O(âœ“) U(âœ“) N(âœ“) D(âœ“)'},\n",
       " {'role': 'assistant', 'content': 'Let me solve this step by step.\\n<think>'}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_messages = get_messages(past_guesses)\n",
    "llm_messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc426e8c-e1c9-493d-8959-e224f9c0da1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From the feedback:\\n- Guess 1: CRANE -> C(x), R(x), A(x), N(âœ“), E(x)\\n  - This means N is in the 4th position and all other letters are incorrect.\\n- Guess 2: BLOND -> B(x), L(x), O(-), N(âœ“), D(âœ“)\\n  - This confirms N is in the 4th position and D is in the 5th position.\\n- Guess 3: FOUND -> F(x), O(âœ“), U(âœ“), N(âœ“), D(âœ“)\\n  - This again confirms N is in the 4th position and D is in the 5th position, and O is in the 2nd position.\\n\\nSo, the word must contain the letters O, N, and D, and the 2nd, 4th, and 5th positions are fixed with these letters. The remaining 1st and 3rd positions are unknown but should be different from the letters already used (C, R, A, B, L, F, U).\\n\\nPossible words that fit these criteria and are 5-letter English words are:\\n- FOUND\\n- ONEDS\\n- ONEDR\\n\\nAmong these, let's choose ONEDS as it's a valid English word and fits the criteria.</think>\\n<guess> ONEDS </guess>\"]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_response_full = generate(llm_messages)\n",
    "llm_response_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a2d5106b-2304-4a6d-a77e-8c91d0f896b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ONEDS'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guessed_word = extract_guess(llm_response_full[0])\n",
    "guessed_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ce33876d-b9d4-4fba-831b-f64edd32b795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guessed word: ONEDS -> Reward: 0\n"
     ]
    }
   ],
   "source": [
    "reward = wordle_reward(guessed_word, secret_word)\n",
    "print(f'Guessed word: {guessed_word} -> Reward: {reward}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1385a3-3328-4a6d-8eb3-579df1f76ca0",
   "metadata": {},
   "source": [
    "The agent ultimately wants to maximize the rewards over time that it receives. To do this, we need diverse responses and those responses need to lead to diverse/different rewards. For example, if the reward function doesn't discriminate well between different responses, it won't work. To work with this, we use the idea of 'advantage', which in turn is just the standardized equivalent of each reward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf3eb074-4469-46b9-8c5b-99738a668235",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_advantages(rewards: list):\n",
    "    rewards = np.array(rewards)\n",
    "\n",
    "    mean_reward = np.mean(rewards)\n",
    "    std_reward = np.std(rewards)\n",
    "\n",
    "    # avoid div by zero when std/var is zero (which happens when all rewards are zero)\n",
    "    if std_reward == 0:\n",
    "        return [0] * len(rewards)\n",
    "\n",
    "    advantages = (rewards - mean_reward) / std_reward\n",
    "    return advantages.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "70964d87-2a80-43c2-91a4-609d478c8980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-1.732050807568877,\n",
       " -1.072221928495019,\n",
       " -0.4123930494211609,\n",
       " -0.08247860988423196,\n",
       " 0.24743582965269698,\n",
       " 0.5773502691896258,\n",
       " 0.9072647087265552,\n",
       " 1.567093587800413]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rewards = [0.0, 0.2, 0.4, 0.5, 0.6, 0.7, 0.8, 1.0]\n",
    "compute_advantages(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "74d3b6b0-248c-4981-812a-2de8d2150fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_guesses_table(extracted_guesses, rewards):\n",
    "    advantages = compute_advantages(rewards)\n",
    "    elems = list(zip(range(len(extracted_guesses)), extracted_guesses, rewards, advantages))\n",
    "\n",
    "    headers = ['Index', 'Guess', 'Reward', 'Advantage']\n",
    "    table = tabulate(elems, headers=headers, tablefmt='grid').split('\\n')\n",
    "    for row in table:\n",
    "        print(row)\n",
    "\n",
    "def render_guess_table(response, reward_fn):\n",
    "    guesses = [extract_guess(guess) for guess in response]\n",
    "    rewards = [reward_fn(guess, secret_word) for guess in guesses]\n",
    "    print_guesses_table(guesses, rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5e01aa7-c404-417b-9ffc-60bd8bc0e317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret: POUND\n",
      "+---------+---------+----------+-------------+\n",
      "|   Index | Guess   |   Reward |   Advantage |\n",
      "+=========+=========+==========+=============+\n",
      "|       0 | FOUNI   |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       1 | MOONED  |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       2 | DONUT   |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       3 | OUND    |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       4 | INDO    |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       5 | BROKE   |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       6 | ONED    |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       7 | FOOLN   |        0 |           0 |\n",
      "+---------+---------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(f'Secret: {secret_word}')\n",
    "response = generate(get_messages(past_guesses), num_guesses=8)\n",
    "render_guess_table(response, wordle_reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9f82f4-a23c-4aff-812c-f6286b2bd54e",
   "metadata": {},
   "source": [
    "So, diversity of responses yeah, but no diversity in rewards/advantage and so no learning's possible. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aaa1f35-2392-498b-bd11-4e3741e98e3b",
   "metadata": {},
   "source": [
    "## Updated reward function to give partial credit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60657c0e-0679-4589-ac6f-674455c0b970",
   "metadata": {},
   "source": [
    "We can be more granular than the binary reward function, which'll indicate when responses are at least marginally better than others, even if they're not the secret word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "b9741539-5ce8-421a-96eb-ed28812b7347",
   "metadata": {},
   "outputs": [],
   "source": [
    "def worldle_reward_partial_credit(guess: str, secret_word: str) -> float:\n",
    "    if len(guess) != len(secret_word):\n",
    "        return 0.0 # no reward for guessing the wrong number of letters\n",
    "\n",
    "    valid_letters = set(secret_word)\n",
    "    reward = 0.0\n",
    "    # each correct letter in the right spot is +0.2, each correct letter in the wrong spot is +0.1\n",
    "    for letter, secret_letter in zip(guess, secret_word):\n",
    "        if letter == secret_letter:\n",
    "            reward += 0.2\n",
    "        elif letter in valid_letters:\n",
    "            reward += 0.1\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    return reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6165015-6128-4364-bfdb-f01bcc8791e0",
   "metadata": {},
   "source": [
    "First, what happens if we just let the model always choose the highest priority response? We'll always get the same guess, which means we'll have no diversity in responses, and everything will have an advantage of zero. Not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f585c52d-9a49-4a6a-8311-7659128910b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret: POUND\n",
      "+---------+---------+----------+-------------+\n",
      "|   Index | Guess   |   Reward |   Advantage |\n",
      "+=========+=========+==========+=============+\n",
      "|       0 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       1 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       2 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       3 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       4 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       5 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       6 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       7 | DOWNY   |      0.5 |           0 |\n",
      "+---------+---------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(f'Secret: {secret_word}')\n",
    "response = generate(get_messages(past_guesses), num_guesses=8, temperature=0)\n",
    "render_guess_table(response, worldle_reward_partial_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2bb2af-20dc-4cdb-a27b-1f9ef939e2db",
   "metadata": {},
   "source": [
    "Now with a relatively high temperature/lots of variation - we'll get some diversity, but also crappy guesses because of the randomness. (Since we're not running multiple iterates and adjusting based on the outputs, I don't think we see any of this now - i.e., these responses and the ones in the next bit w/ temp 0.7 aren't necessarily better/worse.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "99048dc4-3c2e-4a14-880f-cae2d8e69c51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret: POUND\n",
      "+---------+---------+----------+-------------+\n",
      "|   Index | Guess   |   Reward |   Advantage |\n",
      "+=========+=========+==========+=============+\n",
      "|       0 | LANDS   |      0.2 |   -0.46525  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       1 | BOUND   |      0.8 |    1.56493  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       2 | BRICK   |      0   |   -1.14198  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       3 | FOUND   |      0.8 |    1.56493  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       4 | BOND    |      0   |   -1.14198  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       5 | LOOKS   |      0.3 |   -0.126886 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       6 | BLOWN   |      0.2 |   -0.46525  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       7 | FUNNY   |      0.4 |    0.211477 |\n",
      "+---------+---------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(f'Secret: {secret_word}')\n",
    "response = generate(get_messages(past_guesses), num_guesses=8, temperature=1.3)\n",
    "render_guess_table(response, worldle_reward_partial_credit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb15a3-9c3c-465c-950d-cbef906ef62e",
   "metadata": {},
   "source": [
    "And with a more moderate temp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "135fa8da-d19b-4be5-9c8b-da760c59edff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Secret: POUND\n",
      "+---------+---------+----------+-------------+\n",
      "|   Index | Guess   |   Reward |   Advantage |\n",
      "+=========+=========+==========+=============+\n",
      "|       0 | STAND   |      0.4 |   0.641689  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       1 | HOUSE   |      0.4 |   0.641689  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       2 | RINDS   |      0.2 |  -0.825029  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       3 | TOWNS   |      0.4 |   0.641689  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       4 | BOLD    |      0   |  -2.29175   |\n",
      "+---------+---------+----------+-------------+\n",
      "|       5 | GRIND   |      0.4 |   0.641689  |\n",
      "+---------+---------+----------+-------------+\n",
      "|       6 | CURED   |      0.3 |  -0.0916698 |\n",
      "+---------+---------+----------+-------------+\n",
      "|       7 | WORDN   |      0.4 |   0.641689  |\n",
      "+---------+---------+----------+-------------+\n"
     ]
    }
   ],
   "source": [
    "print(f'Secret: {secret_word}')\n",
    "response = generate(get_messages(past_guesses), num_guesses=8, temperature=0.7)\n",
    "render_guess_table(response, worldle_reward_partial_credit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f1a84-d71b-4764-a3e4-1ee1f08e33ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
