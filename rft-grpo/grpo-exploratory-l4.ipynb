{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2cefc0-580f-4b03-a27e-5eff4c405f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # i think this is because the Predibase API sometimes gives warnings for version-related stuff (it does it in the course videos too)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a51e06-e5c4-4af5-b2bf-265a6a51111a",
   "metadata": {},
   "source": [
    "# Lesson four: Reward functions for Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36dc5658-a6d1-43ce-a17f-e40b4635093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"Qwen/Qwen2.5-7B-Instruct\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034b3712-7654-422f-9850-85c154840912",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deployment(name: str):\n",
    "    \"Creates Predibase 'deployment' per utils.py, needed since I'm running this locally and can't use the one they've created, I think.\"\n",
    "    pb = Predibase(api_token=os.environ[\"PREDIBASE_API_TOKEN\"])\n",
    "    try:\n",
    "        pb.deployments.create(\n",
    "            name=name,\n",
    "            config=DeploymentConfig(\n",
    "                accelerator='a10_24gb_100', # cheapest ($2.60/hr), I added this to the code from utils.py, thinking I'd avoid it 'helpfully' picking a more expensive option \n",
    "                base_model=\"qwen2-5-7b-instruct\",\n",
    "                min_replicas=0,\n",
    "                max_replicas=1,\n",
    "                cooldown_time=1200,\n",
    "            )\n",
    "        )\n",
    "    except Exception:\n",
    "        print(f\"Deployment {name} already exists\")\n",
    "\n",
    "create_deployment(private_deployment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce429063-cfec-4662-b04c-341eb7370908",
   "metadata": {},
   "outputs": [],
   "source": [
    "pb = Predibase(api_token=os.environ['PREDIBASE_API_TOKEN'])\n",
    "client = pb.deployments.client(private_deployment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc794085-8288-4b48-9e6f-0416a23180fe",
   "metadata": {},
   "source": [
    "Create a custom deployed instance of the Qwen 2.5 7B instruct model, using Predibase's API, which we'll start using for inference here and then fine-tune - using Predibase's API - below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707a77b-8067-4b47-ac50-1bcd82bbf172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98d551d-4f1c-48ac-9cad-3ee02416e300",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78a3d17c-79ab-42bf-8177-1eebce1a3185",
   "metadata": {},
   "source": [
    "First, I'll try a simple 0/1 reward function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277863fe-5e84-4221-8418-dd05ebec16d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordle_reward(guess: str, secret_word: str) -> int:\n",
    "    if guess.upper() == secret_word.upper():\n",
    "        return 1 # correct\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a48f9b3-fab1-441c-88a1-dabf977e499d",
   "metadata": {},
   "source": [
    "And then I'll define a function from utils.py that gets a new guess from the LLM, by generating a prompt from the template/previous guesses combo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "436eb399-bc54-4e59-bbe6-9e2bd0f3370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from utils.py \n",
    "\n",
    "# in L4 this is defined identically to 'client' above - I think the defn might change in later lessons\n",
    "best_of_client = OpenAI(\n",
    "    base_url=os.environ[\"PREDIBASE_MODEL_QWEN_URL\"],\n",
    "    api_key=os.environ[\"PREDIBASE_API_TOKEN\"],\n",
    ")\n",
    "\n",
    "def generate(\n",
    "    messages: List[dict],\n",
    "    adapter_id: str = \"\",\n",
    "    num_guesses: int = 1,\n",
    "    temperature: float = 0.7,\n",
    "    max_tokens: int = 1024,\n",
    ") -> List[str]:\n",
    "    if temperature > 0.0:\n",
    "        completions = best_of_client.chat.completions.create(\n",
    "            model=adapter_id,\n",
    "            messages=messages,\n",
    "            n=num_guesses,\n",
    "            temperature=temperature,\n",
    "            max_tokens=max_tokens\n",
    "        )\n",
    "        return [choice.message.content for choice in completions.choices]\n",
    "    else:\n",
    "        return [\n",
    "            best_of_client.chat.completions.create(\n",
    "                model=adapter_id,\n",
    "                messages=messages,\n",
    "                n=1,\n",
    "                temperature=temperature,\n",
    "                max_tokens=max_tokens\n",
    "            ).choices[0].message.content for _ in range(num_guesses)\n",
    "        ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
