{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "acb644bc-6362-4fe1-acf1-f16a0e54d5fd",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "I'm using this notebook to reproduce interesting parts of the DeepLearning.ai course [Reinforcement Fine-Tuning LLMs with GRPO](https://learn.deeplearning.ai/courses/reinforcement-fine-tuning-llms-grpo/lesson/sjbja/introduction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505db0f2-6b1e-40d0-9afc-b3e0913d5a6d",
   "metadata": {},
   "source": [
    "# Lesson three: Build an AI that actually plays Wordle, using an LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fbbe9e1-68ce-41c0-8142-e90d44871946",
   "metadata": {},
   "source": [
    "The course first starts doing code in lesson three."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "563302b1-9c3c-4b36-9f57-f47ec8034bac",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "09b4ab99-81a2-410b-bf71-74bb761a15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "\n",
    "from predibase import Predibase, DeploymentConfig\n",
    "\n",
    "private_deployment_name = 'qwen2-5-7b-instruct-dlai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b76ff04-14b5-4560-8996-a4c16804f270",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = load_dotenv(override=True) # populate env from .env file, reload of file - 'override' - ok here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e4a9185-75ac-40b3-959d-9390a1fa5f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">WARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the </span>\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">latest version. Installed: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.3</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Latest: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025.5</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mWARN: Currently installed SDK is outdated. This can lead to bugs or unexpected behavior. Consider upgrading to the \u001b[0m\n",
       "\u001b[1;35mlatest version. Installed: \u001b[0m\u001b[1;36m2025.3\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;35m Latest: \u001b[0m\u001b[1;36m2025.5\u001b[0m\u001b[1;35m.\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;35m.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">Connected to Predibase as </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">User</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">id</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">f66dcd85</span><span style=\"color: #ffff00; text-decoration-color: #ffff00\">-7638-4ead-9487-2506bb2c930b</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">, </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">username</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">=</span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">aenfield</span><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">@gmail.com)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mConnected to Predibase as \u001b[0m\u001b[1;35mUser\u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;33mid\u001b[0m\u001b[1;34m=\u001b[0m\u001b[93mf66dcd85\u001b[0m\u001b[93m-7638-4ead-9487-2506bb2c930b\u001b[0m\u001b[1;34m, \u001b[0m\u001b[1;33musername\u001b[0m\u001b[1;34m=\u001b[0m\u001b[1;35maenfield\u001b[0m\u001b[1;34m@gmail.com\u001b[0m\u001b[1;34m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Predibase provides a OpenAI chat completions v1 endpoint, which is what the tutorial uses\n",
    "# the model URL changes by user and I've created my own based on docs at https://docs.predibase.com/user-guide/inference/migrate-openai\n",
    "client = OpenAI(\n",
    "    base_url=os.environ['PREDIBASE_QWEN_MODEL_URL'], \n",
    "    api_key=os.environ['PREDIBASE_API_TOKEN'],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d61a632-c498-45d9-bd1c-6f55a2e03b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "base_model_id = 'Qwen/Qwen2.5-7B-Instruct'\n",
    "tokenizer = AutoTokenizer.from_pretrained(base_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "68e29817-998c-44d8-b7dc-b2d77112da69",
   "metadata": {},
   "outputs": [],
   "source": [
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are playing Wordle, a word-guessing game.\n",
    "\n",
    "### Game Rules:\n",
    "- You have **6 tries** to guess a secret **5-letter** word.\n",
    "- Each guess must be a valid **5-letter English word**.\n",
    "- After each guess, you will receive feedback indicating how close \n",
    "your guess was.\n",
    "\n",
    "### Feedback Format:\n",
    "Each letter in your guess will receive one of three symbols:\n",
    "1. ✓ : The letter is in the word and in the CORRECT position.\n",
    "2. - : The letter is in the word but in the WRONG position.\n",
    "3. x : The letter is NOT in the word.\n",
    "\n",
    "### Example:\n",
    "Secret Word: BRISK\n",
    "\n",
    "Guess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\n",
    "Guess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\n",
    "Guess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\n",
    "\n",
    "### Response Format:\n",
    "Think through the problem and feedback step by step. Make sure to \n",
    "first add your step-by-step thought process within <think> </think> \n",
    "tags. Then, return your guessed word in the following format: \n",
    "<guess> guessed-word </guess>.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58e742a1-730b-429a-b53a-be521f611401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from enum import Enum\n",
    "from typing import List\n",
    "\n",
    "class LetterFeedback(Enum):\n",
    "    CORRECT = \"✓\"\n",
    "    WRONG_POS = \"-\"\n",
    "    WRONG_LETTER = \"x\"\n",
    "\n",
    "@dataclass\n",
    "class GuessWithFeedback:\n",
    "    guess: str\n",
    "    feedback: List[LetterFeedback]\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        \"A human (and LLM)-readable string showing the guess and letter-by-letter feedback\"\n",
    "        feedback_str = \" \".join(f\"{letter}({fb.value})\" for letter, fb in zip(self.guess, self.feedback))\n",
    "        return f\"{self.guess} -> Feedback: {feedback_str}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3030924-b19c-4d92-9f75-cfcab848e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_user_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    \"Creates a user-facing prompt that includes past guesses and the matching feedback.\"\n",
    "    prompt = \"Make a new 5-letter word guess.\"\n",
    "    if past_guesses:\n",
    "        prompt += \"\\n\\nHere is some previous feedback:\"\n",
    "        for i, guess in enumerate(past_guesses):\n",
    "            prompt += f\"\\nGuess {i+1}: {guess}\"\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "828f5eb5-7d1b-4277-b653-9c57cec3bbca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_prompt(past_guesses: List[GuessWithFeedback]) -> str:\n",
    "    \"\"\"Formats a full chat prompt using a system message, user prompt, and assistant \n",
    "    preamble to start the model's step-by-step reasoning.\"\"\"\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": SYSTEM_PROMPT\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": render_user_prompt(past_guesses)\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"assistant\",\n",
    "            \"content\": \"Let me solve this step by step.\\n<think>\"\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    return tokenizer.apply_chat_template(messages, tokenize=False, continue_final_message=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "dba0f6de-ed7a-405d-98e7-b60301e75d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_stream(prompt: str, adapter_id: str = \"\") -> str:\n",
    "    \"Streams a model-generated response from a prompt in real time, printing as tokens arrive.\"\n",
    "    response = client.completions.create(\n",
    "        model=adapter_id,\n",
    "        prompt=prompt,\n",
    "        temperature=0.0, # deterministic, for evaluation\n",
    "        max_tokens=2048,\n",
    "        stream=True,\n",
    "    )\n",
    "\n",
    "    completion = \"\"\n",
    "    for chunk in response:\n",
    "        if chunk.choices[0].text is not None:\n",
    "            content = chunk.choices[0].text\n",
    "            print(content, end=\"\", flush=True)\n",
    "            completion += content\n",
    "    print\n",
    "\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff65862-87fc-4f9b-ab78-ba393b38d3ae",
   "metadata": {},
   "source": [
    "## Play a single Worldle turn, using the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "828948b1-7156-416c-a3b2-aea108a2fabd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>system\n",
      "\n",
      "You are playing Wordle, a word-guessing game.\n",
      "\n",
      "### Game Rules:\n",
      "- You have **6 tries** to guess a secret **5-letter** word.\n",
      "- Each guess must be a valid **5-letter English word**.\n",
      "- After each guess, you will receive feedback indicating how close \n",
      "your guess was.\n",
      "\n",
      "### Feedback Format:\n",
      "Each letter in your guess will receive one of three symbols:\n",
      "1. ✓ : The letter is in the word and in the CORRECT position.\n",
      "2. - : The letter is in the word but in the WRONG position.\n",
      "3. x : The letter is NOT in the word.\n",
      "\n",
      "### Example:\n",
      "Secret Word: BRISK\n",
      "\n",
      "Guess 1: STORM → Feedback: S(-) T(x) O(x) R(-) M(x)\n",
      "Guess 2: BRAVE → Feedback: B(✓) R(✓) A(x) V(x) E(x)\n",
      "Guess 3: BRISK → Feedback: B(✓) R(✓) I(✓) S(✓) K(✓)\n",
      "\n",
      "### Response Format:\n",
      "Think through the problem and feedback step by step. Make sure to \n",
      "first add your step-by-step thought process within <think> </think> \n",
      "tags. Then, return your guessed word in the following format: \n",
      "<guess> guessed-word </guess>.\n",
      "<|im_end|>\n",
      "<|im_start|>user\n",
      "Make a new 5-letter word guess.\n",
      "\n",
      "Here is some previous feedback:\n",
      "Guess 1: CRANE -> Feedback: C(✓) R(✓) A(✓) N(x) E(x)\n",
      "Guess 2: CRASH -> Feedback: C(✓) R(✓) A(✓) S(x) H(x)<|im_end|>\n",
      "<|im_start|>assistant\n",
      "Let me solve this step by step.\n",
      "<think>\n"
     ]
    }
   ],
   "source": [
    "secret_word = \"CRAFT\"\n",
    "\n",
    "past_guesses = [\n",
    "    GuessWithFeedback(\n",
    "        \"CRANE\", [\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "    GuessWithFeedback(\n",
    "        \"CRASH\", [\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.CORRECT,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "            LetterFeedback.WRONG_LETTER,\n",
    "        ]),\n",
    "]\n",
    "\n",
    "prompt = render_prompt(past_guesses)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ca5d61b3-dc81-4b73-8029-cbd2eaef9136",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Client' object has no attribute 'completions'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m base_completion = \u001b[43mgenerate_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mgenerate_stream\u001b[39m\u001b[34m(prompt, adapter_id)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_stream\u001b[39m(prompt: \u001b[38;5;28mstr\u001b[39m, adapter_id: \u001b[38;5;28mstr\u001b[39m = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      2\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mStreams a model-generated response from a prompt in real time, printing as tokens arrive.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcompletions\u001b[49m.create(\n\u001b[32m      4\u001b[39m         model=adapter_id,\n\u001b[32m      5\u001b[39m         prompt=prompt,\n\u001b[32m      6\u001b[39m         temperature=\u001b[32m0.0\u001b[39m, \u001b[38;5;66;03m# deterministic, for evaluation\u001b[39;00m\n\u001b[32m      7\u001b[39m         max_tokens=\u001b[32m2048\u001b[39m,\n\u001b[32m      8\u001b[39m         stream=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m      9\u001b[39m     )\n\u001b[32m     11\u001b[39m     completion = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n",
      "\u001b[31mAttributeError\u001b[39m: 'Client' object has no attribute 'completions'"
     ]
    }
   ],
   "source": [
    "base_completion = generate_stream(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74cd86d-87b3-4537-8889-e66599ec7416",
   "metadata": {},
   "source": [
    "At this point in the tutorial, they call generate stream but against a model that they've fine-tuned using RFT, and show the much better results. I haven't trained that model yet - I can do it in what they call lesson eight - so can't run the below. (I think that custom fine-tuned models aren't shared, like the base model I'm using above is, so I can't use the one they trained.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3993a9be-2132-403c-aee6-4761e63a3237",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# prompt fine-tuned model\n",
    "# ft_completion = generate_stream(prompt, adapter_id=\"wordle-dlai/2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4f3b57-f0d1-45fa-a412-eb4449f4e0f3",
   "metadata": {},
   "source": [
    "## Playing a complete game of Wordle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a694ed8a-0566-428a-8935-bc8c4470252a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def get_feedback(guess: str, secret_word: str) -> List[LetterFeedback]:\n",
    "    \"Generate a list of tripartite feedback for each letter of the guess.\"\n",
    "    valid_letters = set(secret_word)\n",
    "    feedback = []\n",
    "    for letter, secret_letter in zip(guess, secret_word):\n",
    "        if letter == secret_letter:\n",
    "            feedback.append(LetterFeedback.CORRECT)\n",
    "        elif letter in valid_letters:\n",
    "            feedback.append(LetterFeedback.WRONG_POS)\n",
    "        else:\n",
    "            feedback.append(LetterFeedback.WRONG_LETTER)\n",
    "    return feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b35fa064-dab9-430d-8107-ba67e77ea0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def next_turn(\n",
    "    past_guesses: List[GuessWithFeedback],\n",
    "    secret_word: str,\n",
    "    adapter_id = \"\"\n",
    "):\n",
    "    \"\"\"Do a full turn: build a prompt incorporating previous guesses, \n",
    "    use the LLM to get a new guess, and check and score it.\"\"\"\n",
    "    prompt = render_prompt(past_guesses)\n",
    "    completion = generate_stream(prompt, adapter_id)\n",
    "    \n",
    "    match = re.search(r\"<guess>\\s*(.*?)\\s*</guess>\", completion, re.DOTALL)\n",
    "    if not match:\n",
    "        print(completion)\n",
    "        raise RuntimeError(\"Invalid guess - no guess found in response.\")\n",
    "    guess = match.group(1).upper()\n",
    "    \n",
    "    feedback = get_feedback(guess, secret_word)\n",
    "    past_guesses.append(GuessWithFeedback(guess, feedback))\n",
    "    \n",
    "    print(\"\\n\\n\")\n",
    "    print((\"-\" * 100) + \"\\n\")\n",
    "    for past_guess in past_guesses:\n",
    "        print(past_guess)\n",
    "\n",
    "    if guess == secret_word:\n",
    "        print(\"SUCCESS - win\")\n",
    "    elif len(past_guesses) >= 6:\n",
    "        print(\"LOSS - ran out of guesses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "19d9cb19-ecb9-4cb9-af59-385f7b40d993",
   "metadata": {},
   "outputs": [],
   "source": [
    "secret_word = \"BRICK\"\n",
    "# secret_word = \"STAIR\"\n",
    "past_guesses = []\n",
    "adapter_id = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8fd058eb-b38f-4fe0-ac28-41947cd734d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "- The word is 5 letters long.\n",
      "- We have 6 tries to guess the word.\n",
      "- We need to use valid 5-letter English words.\n",
      "- We should try to gather information about the letters in the word.\n",
      "\n",
      "Since this is the first guess, I'll choose a common 5-letter word that has a mix of vowels and consonants to gather as much information as possible. A good starting word could be \"CRANE\".\n",
      "</think>\n",
      "<guess> CRANE </guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(-) R(✓) A(x) N(x) E(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e06fe04-1078-49ef-9bdd-d7e0d45c9b1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the feedback, we know:\n",
      "- R is in the correct position (2nd letter).\n",
      "- C, A, N, and E are not in the word at all.\n",
      "- The word is 5 letters long and must include R.\n",
      "\n",
      "Given these constraints, we can try to guess a word that fits these criteria and hasn't been used yet. A good approach is to consider common 5-letter words that include R and don't include C, A, N, or E.\n",
      "\n",
      "Some possible words could be:\n",
      "- BREAD\n",
      "- BRISE\n",
      "- BRINE\n",
      "- BRISK\n",
      "\n",
      "I'll choose BREAD as it's a common word and hasn't been used yet.</think>\n",
      "<guess>BREAD</guess>\n",
      "\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n",
      "CRANE -> Feedback: C(-) R(✓) A(x) N(x) E(x)\n",
      "BREAD -> Feedback: B(✓) R(✓) E(x) A(x) D(x)\n"
     ]
    }
   ],
   "source": [
    "next_turn(past_guesses, secret_word, adapter_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47fb442-4121-4bed-8fc8-4ab35d0b2e50",
   "metadata": {},
   "source": [
    "Now, if I had the further trained model, I could try it, and judging from the course video, it'd work well. For now, I don't have a model, as noted above, so can't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fe275dd-deac-4d17-b849-c400339b2b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# secret_word = \"BRICK\"\n",
    "# past_guesses = []\n",
    "# adapter_id = \"wordle-dlai/2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2e8ea838-f48b-4e5e-9a99-579e7ca8d58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next_turn(past_guesses, secret_word, adapter_id)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
